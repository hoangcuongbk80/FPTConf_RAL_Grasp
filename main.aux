\relax 
\citation{hoang2023grasp,hoang2022context,fang2020graspnet}
\citation{du2021vision,hoang2020panoptic,hoang2020object,hoang2016sub}
\citation{du2021vision}
\citation{ten2017grasp,fang2020graspnet,hoang2022context}
\citation{ten2017grasp,liang2019pointnetgpd,du2021vision}
\citation{zou2023object}
\citation{marullo20236d}
\citation{hoang2023grasp}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\newlabel{sec:intro}{{I}{1}}
\citation{bicchi2000robotic,miller2003automatic}
\citation{ten2017grasp}
\citation{liang2019pointnetgpd}
\citation{lou2020learning}
\citation{kokic2020learning}
\citation{schmidt2018grasping}
\citation{yang2021robotic}
\citation{fang2020graspnet}
\citation{ni2020pointnet++}
\citation{hoang2023grasp,hoang2022context}
\citation{hoang2023grasp,hoang2022context}
\citation{saxena2005learning,saxena2008make3d}
\citation{eigen2014depth}
\citation{eigen2015predicting}
\citation{laina2016deeper}
\citation{xu2017multi}
\citation{jiao2018look}
\citation{ramamonjisoa2019sharpnet,zhang2019pattern,lee2019big}
\citation{kendall2018multi}
\citation{yin2019enforcing}
\citation{chen2020improving}
\citation{ranftl2021vision,yang2021transformer}
\@writefile{toc}{\contentsline {section}{\numberline {II}Literature Review}{2}}
\newlabel{sec:relatedwork}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-A}Learning-based Grasp Generation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II-B}Monocular Depth Estimation}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Materials and Methods}{2}}
\newlabel{sec:methodology}{{III}{2}}
\citation{ranftl2021vision}
\citation{piccinelli2023idisc}
\citation{he2016deep}
\citation{qi2017pointnet++}
\citation{zhao2021point,vaswani2017attention}
\citation{woo2018cbam}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Depth Estimation}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Attention-based Adaptive Fusion Network}{3}}
\citation{hu2018squeeze}
\citation{hoang2023grasp}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of our network architecture.\relax }}{4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Overview}{{1}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Voting-based Grasp Generation}{4}}
\newlabel{eq:L_votegrasp_v2}{{9}{4}}
\citation{hoang2023grasp}
\citation{fang2020graspnet}
\citation{fang2020graspnet}
\citation{hoang2022context}
\citation{hoang2022context}
\citation{qi2017pointnet++}
\citation{qi2017pointnet++}
\citation{qi2017pointnet++}
\citation{qi2017pointnet++}
\citation{fang2020graspnet}
\citation{ten2017grasp,fang2020graspnet}
\citation{morrison2018closing}
\citation{chu2018real}
\citation{ten2017grasp}
\citation{liang2019pointnetgpd}
\citation{fang2020graspnet}
\citation{gou2021rgb}
\citation{sundermeyer2021contact}
\citation{hoang2022context}
\citation{fang2020graspnet}
\citation{fang2020graspnet,gou2021rgb}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Dataset}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Result and Discussion}{5}}
\newlabel{sec:evaluation}{{IV}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Implementation Details}{5}}
\newlabel{sec:implement}{{IV-A}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Layer parameters of PointNet++ \cite  {qi2017pointnet++} based feature learning network.\relax }}{5}}
\newlabel{tab:layer_specs}{{I}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Evaluation on GraspNet-1Billion}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Examples of input scenes and predicted grasps from VoteGrasp \cite  {hoang2022context} and the proposed method. The different intensity of grasp color denotes the confidence score of grasps. Green refers to the highest quality grasps and red refers to the lowest ones.\relax }}{6}}
\newlabel{fig:grasp_result}{{2}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The table shows the results on GraspNet-1Billion test set captured by RealSense/Kinect sensors respectively.\relax }}{6}}
\newlabel{tab:grasp_detect_eval}{{II}{6}}
\citation{ten2017grasp}
\citation{liang2019pointnetgpd}
\citation{fang2020graspnet}
\citation{gou2021rgb}
\citation{sundermeyer2021contact}
\citation{hoang2022context}
\citation{ten2017grasp}
\citation{liang2019pointnetgpd}
\citation{sundermeyer2021contact}
\bibstyle{IEEEtran}
\bibdata{References}
\bibcite{hoang2023grasp}{1}
\bibcite{hoang2022context}{2}
\bibcite{fang2020graspnet}{3}
\bibcite{du2021vision}{4}
\bibcite{hoang2020panoptic}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Comparison of running speed (Hz) and AP on GraspNet-1Billion dataset.\relax }}{7}}
\newlabel{fig:runtime}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Robotic Grasping Experiment}{7}}
\newlabel{sec:real_grasping}{{IV-C}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Real-world grasping experiment.\relax }}{7}}
\newlabel{fig:robot1}{{4}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Results of real robot experiments. The networks were trained on the GraspNet-1Billion dataset. The table shows the number of attempts, the number of successful attempts, and the grasp success rate.\relax }}{7}}
\newlabel{tab:real_grasping}{{III}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusions}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
\bibcite{hoang2020object}{6}
\bibcite{hoang2016sub}{7}
\bibcite{ten2017grasp}{8}
\bibcite{liang2019pointnetgpd}{9}
\bibcite{zou2023object}{10}
\bibcite{marullo20236d}{11}
\bibcite{bicchi2000robotic}{12}
\bibcite{miller2003automatic}{13}
\bibcite{lou2020learning}{14}
\bibcite{kokic2020learning}{15}
\bibcite{schmidt2018grasping}{16}
\bibcite{yang2021robotic}{17}
\bibcite{ni2020pointnet++}{18}
\bibcite{saxena2005learning}{19}
\bibcite{saxena2008make3d}{20}
\bibcite{eigen2014depth}{21}
\bibcite{eigen2015predicting}{22}
\bibcite{laina2016deeper}{23}
\bibcite{xu2017multi}{24}
\bibcite{jiao2018look}{25}
\bibcite{ramamonjisoa2019sharpnet}{26}
\bibcite{zhang2019pattern}{27}
\bibcite{lee2019big}{28}
\bibcite{kendall2018multi}{29}
\bibcite{yin2019enforcing}{30}
\bibcite{chen2020improving}{31}
\bibcite{ranftl2021vision}{32}
\bibcite{yang2021transformer}{33}
\bibcite{piccinelli2023idisc}{34}
\bibcite{he2016deep}{35}
\bibcite{qi2017pointnet++}{36}
\bibcite{zhao2021point}{37}
\bibcite{vaswani2017attention}{38}
\bibcite{woo2018cbam}{39}
\bibcite{hu2018squeeze}{40}
\bibcite{morrison2018closing}{41}
\bibcite{chu2018real}{42}
\bibcite{gou2021rgb}{43}
\bibcite{sundermeyer2021contact}{44}
